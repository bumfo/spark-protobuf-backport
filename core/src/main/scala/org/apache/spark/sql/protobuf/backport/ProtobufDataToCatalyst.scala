/*
 * Backport of Spark 3.4's ProtobufDataToCatalyst to Spark 3.2.1.
 *
 * This version has been enhanced to support deserializing Protobuf
 * binaries directly into Spark's InternalRow without going through
 * DynamicMessage when a compiled Java class is available.  When the
 * message name points at a generated Protobuf Java class (and neither
 * a descriptor file path nor a binary descriptor set is provided) we
 * use reflection to load the class, parse the binary using the
 * class's static `parseFrom` method and then convert the resulting
 * message into an InternalRow using a Parser generated by
 * fastproto.ProtoToRowGenerator.  This avoids the overhead of
 * DynamicMessage and allows users to work with compiled messages.
 */

package org.apache.spark.sql.protobuf.backport

import com.google.protobuf.{Descriptors, Message => PbMessage}
import fastproto._
import org.apache.spark.internal.Logging
import org.apache.spark.sql.catalyst.expressions.codegen.{CodeGenerator, CodegenContext, ExprCode}
import org.apache.spark.sql.catalyst.expressions.{ExpectsInputTypes, Expression, UnaryExpression}
import org.apache.spark.sql.catalyst.util.{FailFastMode, ParseMode, PermissiveMode}
import org.apache.spark.sql.protobuf.backport.shims.{QueryCompilationErrors, QueryExecutionErrors}
import org.apache.spark.sql.protobuf.backport.utils.{ProtobufOptions, ProtobufUtils, SchemaConverters}
import org.apache.spark.sql.types.{AbstractDataType, BinaryType, StructType}
import org.apache.spark.util.Utils

import scala.util.control.NonFatal

/**
 * A Catalyst expression that deserializes a Protobuf binary column into a
 * Catalyst value.  If parsing fails it either returns null (permissive mode)
 * or throws an exception (fail‑fast mode).
 *
 * When a compiled Protobuf class is available (i.e. `messageName` refers
 * directly to a Java class and both `descFilePath` and `binaryDescriptorSet`
 * are empty) the binary is parsed using the class's `parseFrom` method and
 * converted into an InternalRow via a generated [[fastproto.Parser]].
 * Otherwise this falls back to Spark's original DynamicMessage‑based
 * deserialization path.
 *
 * @param child               The binary column to deserialize.
 * @param messageName         The fully qualified message name or Java class name.
 * @param descFilePath        Optional path to a serialized descriptor file.  If
 *                            provided the descriptor will be loaded from the file;
 *                            otherwise `messageName` is treated as a Java class name.
 * @param options             Reader options; currently supports "mode" (permissive|failfast)
 *                            and "recursive.fields.max.depth".
 * @param binaryDescriptorSet Optional binary descriptor set.  If defined, this
 *                            descriptor will be used to build the message descriptor
 *                            instead of reading from a file on the executors.  This
 *                            allows the descriptor to be serialized with the
 *                            expression and avoids file availability issues.
 */
private[backport] case class ProtobufDataToCatalyst(
    child: Expression,
    messageName: String,
    descFilePath: Option[String] = None,
    options: Map[String, String] = Map.empty,
    binaryDescriptorSet: Option[Array[Byte]] = None)
  extends UnaryExpression
    with ExpectsInputTypes
    with Logging {

  override def inputTypes: Seq[AbstractDataType] = Seq(BinaryType)

  private lazy val protobufOptions: ProtobufOptions = ProtobufOptions(options)

  private case class Plan(
      schema: StructType,
      parserKind: ParserKind,
      compiledClassName: Option[String])

  private sealed trait ParserKind extends Serializable

  private object ParserKind {
    case object Generated extends ParserKind

    case object WireFormat extends ParserKind

    case object Dynamic extends ParserKind
  }

  private lazy val plan: Plan = buildPlan()

  override lazy val dataType: StructType = plan.schema

  override def nullable: Boolean = true

  // Determine parse mode once up front.
  private lazy val parseMode: ParseMode = {
    val mode = protobufOptions.parseMode
    if (mode != PermissiveMode && mode != FailFastMode) {
      throw QueryCompilationErrors.parseModeUnsupportedError(prettyName, mode)
    }
    mode
  }

  @transient private var descriptorCache: Descriptors.Descriptor = _

  @transient private lazy val parserLocal = new ThreadLocal[Parser] {
    override protected def initialValue(): Parser = createParser(plan)
  }

  @transient private lazy val writerLocal = new ThreadLocal[NullDefaultRowWriter] {
    override protected def initialValue(): NullDefaultRowWriter =
      new NullDefaultRowWriter(plan.schema.length)
  }

  def parser: Parser = parserLocal.get()

  def writer: NullDefaultRowWriter = writerLocal.get()

  def newWriter: NullDefaultRowWriter = new NullDefaultRowWriter(plan.schema.length)

  override def nullSafeEval(input: Any): Any = {
    val binary = input.asInstanceOf[Array[Byte]]
    try {
      parser.parse(binary)
    } catch {
      case NonFatal(e) => handleException(e)
    }
  }

  override def prettyName: String = "from_protobuf"

  override protected def doGenCode(ctx: CodegenContext, ev: ExprCode): ExprCode = {
    val expr = ctx.addReferenceObj("this", this)
    nullSafeCodeGen(
      ctx,
      ev,
      eval => {
        val result = ctx.freshName("result")
        val dt = CodeGenerator.boxedType(dataType)
        s"""
           |$dt $result = ($dt) $expr.nullSafeEval($eval);
           |if ($result == null) {
           |  ${ev.isNull} = true;
           |} else {
           |  ${ev.value} = $result;
           |}
           |""".stripMargin
      }
    )
  }

  override protected def withNewChildInternal(newChild: Expression): ProtobufDataToCatalyst =
    copy(child = newChild)

  private def buildPlan(): Plan = {
    val desc = descriptor()

    val compiledClassName = (descFilePath, binaryDescriptorSet) match {
      case (None, None) =>
        try {
          Some(Class.forName(messageName).asInstanceOf[Class[PbMessage]].getName)
        } catch {
          case _: Throwable => None
        }
      case _ => None
    }

    val parserKind =
      if (compiledClassName.isDefined) ParserKind.Generated
      else if (binaryDescriptorSet.isDefined) ParserKind.WireFormat
      else ParserKind.Dynamic

    val schema: StructType = parserKind match {
      case ParserKind.WireFormat =>
        RecursiveSchemaConverters.toSqlTypeWithTrueRecursion(desc, enumAsInt = true)
      case _ =>
        SchemaConverters.toSqlType(desc, protobufOptions).dataType
    }

    Plan(schema, parserKind, compiledClassName)
  }

  private def descriptor(): Descriptors.Descriptor = {
    if (descriptorCache == null) {
      this.synchronized {
        if (descriptorCache == null) {
          descriptorCache = binaryDescriptorSet match {
            case Some(bytes) => ProtobufUtils.buildDescriptorFromBytes(bytes, messageName)
            case None => ProtobufUtils.buildDescriptor(messageName, descFilePath)
          }
        }
      }
    }
    descriptorCache
  }

  private def createParser(plan: Plan): Parser = plan.parserKind match {
    case ParserKind.Generated =>
      val cls = Utils.classForName(plan.compiledClassName.get).asInstanceOf[Class[PbMessage]]
      ProtoToRowGenerator.generateParser(descriptor(), cls, plan.schema)

    case ParserKind.WireFormat =>
      try {
        WireFormatToRowGenerator.generateParser(descriptor(), plan.schema)
      } catch {
        case NonFatal(e) if parseMode == PermissiveMode =>
          logWarning(
            s"Failed to generate wire format parser for message $messageName, falling back to DynamicMessage parsing: ${e.getMessage}")
          new DynamicMessageParser(descriptor(), plan.schema)
      }

    case ParserKind.Dynamic =>
      new DynamicMessageParser(descriptor(), plan.schema)
  }

  /**
   * Handle an exception according to the configured parse mode.
   */
  private def handleException(e: Throwable): Any = {
    e match {
      case _: org.codehaus.commons.compiler.CompileException =>
        throw e
      case NonFatal(_) =>
        parseMode match {
          case PermissiveMode => null
          case FailFastMode =>
            throw QueryExecutionErrors.malformedProtobufMessageDetectedInMessageParsingError(e)
          case _ =>
            throw QueryCompilationErrors.parseModeUnsupportedError(prettyName, parseMode)
        }
    }
  }
}
